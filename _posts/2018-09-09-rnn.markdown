---
layout: post
comments: true
title:  "Mạng nơ-ron hồi quy (RNN) và mạng Bộ nhớ ngắn hạn dài (LSTM) (Phần 1)"
excerpt: "Mô hình học đứng đằng sau thành công của những ứng dụng như Dịch tự động (machine translation), Nhận dạng tiếng nói (Speech recognition) hay Hệ hỏi đáp (Question answering system),.."
date:   2018-09-09 11:00:00
mathjax: true
---

# Mục lục
* [Giới thiệu về RNN](#introduction)
* [Huấn luyện một RNN](#training)
* [Thách thức trong việc học các phụ thuộc dài hạn](#challenge)
* [Bộ nhớ ngắn hạn dài (LSTM)](#lstm)
* [Lập trình RNN](#coding)
* [Tài liệu tham khảo](#references)

### Giới thiệu về RNN <a name="introduction"></a>

Nếu như **Mạng nơ-ron tích chập (Convolutional neural network - CNN)** là mô hình mạng nơ-ron chuyên dùng cho loại dữ liệu có dạng lưới hai chiều như hình ảnh thì **Mạng nơ-ron hồi quy (Recurrent neural network)** hay **RNN** là một nhánh của mạng nơ-ron nhân tạo được thiết kế đặc biệt cho việc mô hình hóa dữ liệu có tính chất nối tiếp nhau - dữ liệu dạng chuỗi (sequential data). Khác với dữ liệu ảnh (mỗi ảnh được xem là một điểm dữ liệu riêng biệt) thì dữ liệu chuỗi xem các điểm dữ liệu có phía sau có mối liên hệ chặt chẽ với những điểm dữ liệu trước nó. Lấy ví dụ về một dạng dữ liệu chuỗi: các từ trong một câu, ví dụ _"Paris là thủ đô của nước\_\_"_, dễ biết rằng từ duy nhất phù hợp để viết tiếp trong câu trên là _"Pháp"_ - từ được tạo ra dưới mối liên hệ của các từ trước đó. Các khung hình trong một bộ phim hay giá cổ phiếu trong vòng một tuần cũng là những ví dụ của loại dữ liệu chuỗi.

Vấn đề lớn nhất gặp phải khi xử lý chúng là người ta không biết một điểm dữ liệu có liên hệ với bao nhiêu điểm dữ liệu phía trước nó để đưa vào mô hình, cái mà yêu cầu chuỗi đầu vào phải có kích thước cố định. Xét bài toán _mô hình hóa ngôn ngữ_ (language modeling) - bài toán dự đoán từ tiếp theo trong một chuỗi các từ cho trước. Mối quan hệ phụ thuộc có thể ngắn như trong câu _"Ai cũng biết rằng, mặt trời mọc đằng đông"_ mối quan hệ của từ **đông** chỉ dài đến **mặt trời** cách nó 2 từ, hoặc thậm chí dài như câu _"Con gì đầu rồng đuôi phụng cánh tiên, ngày năm bảy vợ, tối ngủ riêng một mình ?"_, trong câu này, dấu **chấm hỏi (?)** phụ thuộc đến từ để hỏi ở đầu câu - **con gì** cách nó 17 từ. Trước đây, một trong những cách phổ biến được dùng đó là _giả định về sự phụ thuộc_, nó nói rằng một điểm dữ liệu trong chuỗi chỉ phụ thuộc với một số lượng nhất định $$N$$ điểm dữ liệu trước đó. Rõ ràng giả định này là sai với $$N$$ bất kỳ (như trong trường hợp dấu chấm hỏi và từ để hỏi: một câu hỏi có thể dài vô hạn từ), tuy nhiên nó đã được áp dụng trong các mô hình như xử lý tiếng nói hay mô hình hóa ngôn ngữ.

Khác với các mô hình sử dụng giả định về phụ thuộc, mạng RNN, trên lý thuyết, có khả năng nắm bắt được sự phụ thuộc với độ dài bất kỳ. Để làm được điều đó, trong quá trình học, RNN sử dụng một loại _bộ nhớ_ được gọi là _trạng thái ẩn_. Hình 1. miêu tả một mô hình RNN đơn giản, trong đó __RNN cell__ là một đơn vị tính toán, nó nhận vào một _đầu vào_ (input) và một _trạng thái ẩn_ (hidden state) ở thời điểm trước đó để tạo ra một _đầu ra_ (output) và một trạng thái ẩn tại thời điểm tiếp theo. Có thể hình dung mô hình này như một vòng lặp duyệt qua tất cả các phần tử của một chuỗi đầu vào, tương ứng với từng phần tử thì RNN cell sẽ tạo ra một đầu ra và một trạng thái ẩn. Trạng thái ẩn đó sẽ được truyền đi cho việc tính toán ở đầu vào ngay sau nó. Với mỗi lần RNN cell tính toán một đầu vào, ta gọi nó là một _bước thời gian_ (time step).

<p align="center">
  <img src="http://farm2.staticflickr.com/1904/45027635721_78f337c8f5_b.jpg">
  <br>
  <br>
  Hình 1. Mô hình RNN đơn giản tại một bước thời gian
</p>

Với một số lượng hữu hạn các bước thời gian, mô hình trong Hình 1. có thể được khai triển ra như trong Hình 2.

<p align="center">
  <img src="http://farm2.staticflickr.com/1956/44329996054_01f9ea900c_b.jpg">
  <br>
  <br>
  Hình 1. Mô hình RNN đơn giản được khai triển ra trên nhiều bước thời gian
</p>




### Lập trình Pytorch <a name="coding"></a>


### Tài liệu tham khảo <a name="references"></a>
\[1\]: https://pytorch.org/